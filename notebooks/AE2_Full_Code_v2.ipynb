{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_8bEwiaYjF-"
      },
      "outputs": [],
      "source": [
        "Try AI directly in your favourite apps … Use Gemini to generate drafts and refine content, plus get Gemini Pro with access to Google's next-gen AI for £18.99 £0 for 1 month\n",
        "# ============================================================================\n",
        "# PROJECT: Probabilistic Round-Win Prediction in CS2 (AE2)\n",
        "# AUTHOR: FA25433\n",
        "# TYPE: Implementation Pipeline (Python Script)\n",
        "# ============================================================================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import json\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import lightgbm as lgb\n",
        "from datetime import datetime\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from sklearn.metrics import log_loss, brier_score_loss, roc_auc_score, accuracy_score\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "# Ignore standard warnings to keep the output clean for presentation\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION & PATH SETUP (CRITICAL FOR GITHUB)\n",
        "# ============================================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"STEP 0: INITIALISATION AND PATH SETUP\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Define directories using relative paths\n",
        "# 'data' folder for inputs, 'progression' folder for outputs\n",
        "BASE_DIR = os.getcwd()\n",
        "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, 'progression')\n",
        "\n",
        "# Create the output directory if it does not exist\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)\n",
        "    print(f\" Created directory: {OUTPUT_DIR}\")\n",
        "\n",
        "# Define file paths\n",
        "# Note: Ensure 'matches.xlsx' and 'freeze_time_features.csv' are in the 'data' folder\n",
        "FREEZE_TIME_FILE = os.path.join(DATA_DIR, 'freeze_time_features.csv')\n",
        "MATCHES_FILE = os.path.join(DATA_DIR, 'matches.xlsx')\n",
        "\n",
        "print(f\" Working Directory: {BASE_DIR}\")\n",
        "print(f\" Input Data:        {DATA_DIR}\")\n",
        "print(f\" Output Progression:{OUTPUT_DIR}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: LOADING DATA\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 1: LOADING RAW DATASETS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Load the freeze-time features (round-by-round data)\n",
        "print(f\"Loading rounds data from: {FREEZE_TIME_FILE}\")\n",
        "if os.path.exists(FREEZE_TIME_FILE):\n",
        "    df_rounds = pd.read_csv(FREEZE_TIME_FILE)\n",
        "    print(f\" Loaded {len(df_rounds):,} rows from freeze_time_features.csv\")\n",
        "else:\n",
        "    print(f\" ERROR: Could not find {FREEZE_TIME_FILE}\")\n",
        "    sys.exit(1) # Stop the programme if data is missing\n",
        "\n",
        "# Load the match metadata (for Elo calculation)\n",
        "print(f\"\\nLoading matches metadata from: {MATCHES_FILE}\")\n",
        "if os.path.exists(MATCHES_FILE):\n",
        "    df_matches = pd.read_excel(MATCHES_FILE)\n",
        "    print(f\" Loaded {len(df_matches):,} rows from matches.xlsx\")\n",
        "    # Ensure time column is datetime format for chronological sorting\n",
        "    df_matches['Time'] = pd.to_datetime(df_matches['Time'])\n",
        "else:\n",
        "    print(f\" ERROR: Could not find {MATCHES_FILE}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: ELO RATING CONSTRUCTION (INTEGRITY STEP)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 2: FEATURE ENGINEERING & ELO RATING CONSTRUCTION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 2.1 Extract Series Type\n",
        "def extract_series_type(maps_str):\n",
        "    \"\"\"Extract if match is Best-of-1, Best-of-3, etc.\"\"\"\n",
        "    if pd.isna(maps_str): return 1\n",
        "    maps_str = str(maps_str).lower().strip()\n",
        "    if 'bo5' in maps_str: return 5\n",
        "    elif 'bo3' in maps_str: return 3\n",
        "    elif 'bo2' in maps_str: return 2\n",
        "    elif 'bo1' in maps_str: return 1\n",
        "    else: return 3 # Default assumption\n",
        "\n",
        "df_matches['series_type'] = df_matches['Maps'].apply(extract_series_type)\n",
        "\n",
        "# 2.2 Prepare Data for Elo\n",
        "# We create a clean, sorted dataframe for the Elo calculation loop\n",
        "df_matches_elo = df_matches[['Match ID', 'Time', 'Event Name', 'Team 1', 'Team 2', 'Result 1', 'Result 2', 'series_type']].copy()\n",
        "df_matches_elo.columns = ['match_id', 'match_time', 'event_name', 'team1', 'team2', 'score1', 'score2', 'series_type']\n",
        "df_matches_elo = df_matches_elo.sort_values('match_time').reset_index(drop=True)\n",
        "\n",
        "# 2.3 Elo Class Implementation\n",
        "class EloRatingSystem:\n",
        "    \"\"\"\n",
        "    Custom Elo system that supports 'Freezing' ratings before an event.\n",
        "    This prevents data leakage by ensuring predictions only use past knowledge.\n",
        "    \"\"\"\n",
        "    def __init__(self, k_factor=32, default_rating=1500):\n",
        "        self.k_factor = k_factor\n",
        "        self.default_rating = default_rating\n",
        "        self.ratings = {}  # Live ratings\n",
        "        self.event_ratings = {}  # Frozen ratings (The Integrity Lock)\n",
        "        self.rating_history = []\n",
        "\n",
        "    def get_rating(self, team):\n",
        "        return self.ratings.get(team, self.default_rating)\n",
        "\n",
        "    def expected_score(self, rating_a, rating_b):\n",
        "        return 1 / (1 + 10 ** ((rating_b - rating_a) / 400))\n",
        "\n",
        "    def freeze_rating_for_event(self, team, event):\n",
        "        \"\"\"Snapshots the rating at the start of the tournament.\"\"\"\n",
        "        key = (team, event)\n",
        "        if key not in self.event_ratings:\n",
        "            self.event_ratings[key] = self.get_rating(team)\n",
        "\n",
        "    def get_pre_event_rating(self, team, event):\n",
        "        \"\"\"Retrieves the frozen rating to use for prediction.\"\"\"\n",
        "        key = (team, event)\n",
        "        # Fallback logic if event not tracked yet\n",
        "        if key not in self.event_ratings:\n",
        "            self.event_ratings[key] = self.get_rating(team)\n",
        "\n",
        "        rating = self.event_ratings[key]\n",
        "        # Check if team is new (has history?)\n",
        "        has_history = any(h['team_a'] == team or h['team_b'] == team for h in self.rating_history)\n",
        "        return rating, 0 if has_history else 1\n",
        "\n",
        "    def update_ratings(self, team_a, team_b, score_a, score_b, match_id, match_time):\n",
        "        \"\"\"Updates live ratings after a match concludes.\"\"\"\n",
        "        ra, rb = self.get_rating(team_a), self.get_rating(team_b)\n",
        "        total = score_a + score_b\n",
        "        actual_a = score_a / total if total > 0 else 0.5\n",
        "        expected_a = self.expected_score(ra, rb)\n",
        "\n",
        "        new_ra = ra + self.k_factor * (actual_a - expected_a)\n",
        "        new_rb = rb + self.k_factor * ((1 - actual_a) - (1 - expected_a))\n",
        "\n",
        "        self.ratings[team_a] = new_ra\n",
        "        self.ratings[team_b] = new_rb\n",
        "\n",
        "        self.rating_history.append({\n",
        "            'match_id': match_id, 'team_a': team_a, 'team_b': team_b,\n",
        "            'rating_a_after': new_ra, 'rating_b_after': new_rb\n",
        "        })\n",
        "\n",
        "# Initialise the system\n",
        "elo_system = EloRatingSystem(k_factor=32, default_rating=1500)\n",
        "processed_events = set()\n",
        "match_elo_data = []\n",
        "\n",
        "print(\" Calculating chronological Elo ratings...\")\n",
        "\n",
        "# 2.4 Run the Chronological Loop\n",
        "for idx, row in df_matches_elo.iterrows():\n",
        "    event = row['event_name']\n",
        "\n",
        "    # FREEZE LOGIC: If this is a new event, snapshot everyone's ratings\n",
        "    if event not in processed_events:\n",
        "        event_matches = df_matches_elo[df_matches_elo['event_name'] == event]\n",
        "        event_teams = set(event_matches['team1'].tolist() + event_matches['team2'].tolist())\n",
        "        for team in event_teams:\n",
        "            elo_system.freeze_rating_for_event(team, event)\n",
        "        processed_events.add(event)\n",
        "\n",
        "    # Get the SAFE ratings for this match\n",
        "    t1_elo, t1_miss = elo_system.get_pre_event_rating(row['team1'], event)\n",
        "    t2_elo, t2_miss = elo_system.get_pre_event_rating(row['team2'], event)\n",
        "\n",
        "    match_elo_data.append({\n",
        "        'match_id': row['match_id'],\n",
        "        'team1': row['team1'],\n",
        "        'team2': row['team2'],\n",
        "        'team1_elo_pre_event': t1_elo,\n",
        "        'team2_elo_pre_event': t2_elo,\n",
        "        'elo_diff_team1': t1_elo - t2_elo,\n",
        "        'team1_elo_missing': t1_miss,\n",
        "        'team2_elo_missing': t2_miss\n",
        "    })\n",
        "\n",
        "    # Update live ratings (for the future)\n",
        "    elo_system.update_ratings(row['team1'], row['team2'], row['score1'], row['score2'], row['match_id'], row['match_time'])\n",
        "\n",
        "df_match_elo = pd.DataFrame(match_elo_data)\n",
        "print(f\" Ratings calculated for {len(df_match_elo)} matches.\")\n",
        "\n",
        "# 2.5 Merge Elo into Round Data\n",
        "print(\" Merging Elo ratings into round data...\")\n",
        "# Optimised mapping using dictionary for speed\n",
        "elo_lookup = {row['match_id']: row for _, row in df_match_elo.iterrows()}\n",
        "\n",
        "# Lists to construct new columns\n",
        "team_elos, opp_elos, elo_diffs, elo_missings = [], [], [], []\n",
        "\n",
        "for _, row in df_rounds.iterrows():\n",
        "    m_data = elo_lookup.get(row['match_id'])\n",
        "    if m_data is None:\n",
        "        # Default if match missing (shouldn't happen)\n",
        "        team_elos.append(1500); opp_elos.append(1500); elo_diffs.append(0); elo_missings.append(1)\n",
        "        continue\n",
        "\n",
        "    if row['team_name'] == m_data['team1']:\n",
        "        team_elos.append(m_data['team1_elo_pre_event'])\n",
        "        opp_elos.append(m_data['team2_elo_pre_event'])\n",
        "        elo_diffs.append(m_data['elo_diff_team1'])\n",
        "        elo_missings.append(m_data['team1_elo_missing'])\n",
        "    else:\n",
        "        team_elos.append(m_data['team2_elo_pre_event'])\n",
        "        opp_elos.append(m_data['team1_elo_pre_event'])\n",
        "        elo_diffs.append(-m_data['elo_diff_team1']) # Flip the difference\n",
        "        elo_missings.append(m_data['team2_elo_missing'])\n",
        "\n",
        "df_rounds['team_elo_pre_event'] = team_elos\n",
        "df_rounds['opp_elo_pre_event'] = opp_elos\n",
        "df_rounds['elo_diff'] = elo_diffs\n",
        "df_rounds['elo_missing'] = elo_missings\n",
        "\n",
        "# Merge Event Name for grouping\n",
        "df_rounds = df_rounds.merge(df_matches[['Match ID', 'Event Name']].rename(columns={'Match ID':'match_id', 'Event Name':'event_name'}), on='match_id', how='left')\n",
        "\n",
        "# Save intermediate file to progression\n",
        "df_rounds.to_csv(os.path.join(OUTPUT_DIR, 'rounds_with_elo.csv'), index=False)\n",
        "print(\" Elo Integration Complete. Saved 'rounds_with_elo.csv'.\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: DATA PREPARATION & SPLITTING\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 3: PREPARING MATRICES FOR TRAINING\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Feature Definitions\n",
        "FEATURES_NUMERIC = [\n",
        "    'score_diff', 'start_cash', 'loss_bonus', 'consec_losses', 'equip_value',\n",
        "    'rifle_cnt', 'smg_cnt', 'shotgun_cnt', 'awp_cnt',\n",
        "    'helmets', 'kevlar', 'kits',\n",
        "    'flash_cnt', 'smoke_cnt', 'he_cnt', 'molotov_cnt',\n",
        "    'opp_rifle_cnt', 'opp_smg_cnt', 'opp_awp_cnt', # Key opponent gears\n",
        "    'timeout_flag'\n",
        "]\n",
        "FEATURES_ELO = ['team_elo_pre_event', 'opp_elo_pre_event', 'elo_diff', 'elo_missing']\n",
        "FEATURES_CAT = ['map', 'side']\n",
        "TARGET = 'round_win'\n",
        "\n",
        "# One-Hot Encoding for Categorical Features\n",
        "print(\" Encoding categorical features...\")\n",
        "df_encoded = pd.get_dummies(df_rounds, columns=FEATURES_CAT, drop_first=True)\n",
        "\n",
        "# Define feature lists dynamically based on encoded columns\n",
        "encoded_cols = [c for c in df_encoded.columns if c.startswith('map_') or c.startswith('side_')]\n",
        "features_freeze = FEATURES_NUMERIC + encoded_cols\n",
        "features_full = features_freeze + FEATURES_ELO\n",
        "\n",
        "# Time-Aware Splitting\n",
        "# We group by EVENT to ensure no data leakage between training and testing\n",
        "# The last 2 events are held out as the Test Set.\n",
        "unique_events = df_encoded['event_name'].unique()\n",
        "event_to_id = {evt: i for i, evt in enumerate(sorted(unique_events))}\n",
        "df_encoded['event_group'] = df_encoded['event_name'].map(event_to_id)\n",
        "\n",
        "test_groups = [len(unique_events)-1, len(unique_events)-2] # Last 2 events\n",
        "train_mask = ~df_encoded['event_group'].isin(test_groups)\n",
        "\n",
        "# Create matrices\n",
        "X_train_full = df_encoded.loc[train_mask, features_full]\n",
        "y_train = df_encoded.loc[train_mask, TARGET]\n",
        "X_test_full = df_encoded.loc[~train_mask, features_full]\n",
        "y_test = df_encoded.loc[~train_mask, TARGET]\n",
        "\n",
        "# Groups for CV\n",
        "groups_train = df_encoded.loc[train_mask, 'event_group']\n",
        "\n",
        "print(f\" Train Shape: {X_train_full.shape}\")\n",
        "print(f\" Test Shape:  {X_test_full.shape}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 4: BASELINE MODELS (ABLATION STUDY)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 4: TRAINING BASELINE MODELS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Baseline B: Logistic Regression (No Elo) - The \"Economy Only\" Model\n",
        "print(\" Training Baseline B (No Elo)...\")\n",
        "# We filter X_train_full to only include freeze-time features (exclude Elo)\n",
        "X_train_freeze = X_train_full[features_freeze]\n",
        "X_test_freeze = X_test_full[features_freeze]\n",
        "\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_model.fit(X_train_freeze, y_train)\n",
        "y_pred_baseline = lr_model.predict_proba(X_test_freeze)[:, 1]\n",
        "\n",
        "loss_base = log_loss(y_test, y_pred_baseline)\n",
        "print(f\" Baseline B Log Loss: {loss_base:.4f}\")\n",
        "\n",
        "# Baseline B+: Logistic Regression (With Elo) - To quantify Elo value\n",
        "print(\" Training Baseline B+ (With Elo)...\")\n",
        "lr_elo_model = LogisticRegression(max_iter=1000)\n",
        "lr_elo_model.fit(X_train_full, y_train)\n",
        "y_pred_base_elo = lr_elo_model.predict_proba(X_test_full)[:, 1]\n",
        "\n",
        "loss_base_elo = log_loss(y_test, y_pred_base_elo)\n",
        "print(f\" Baseline B+ Log Loss: {loss_base_elo:.4f}\")\n",
        "print(f\" Improvement from Elo: {loss_base - loss_base_elo:.4f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 5: MAIN MODEL (LightGBM + CALIBRATION)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 5: TRAINING MAIN MODEL (LightGBM)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Create a validation split for Early Stopping & Calibration\n",
        "# We take one event group out of the training set to be the validation set\n",
        "val_group = groups_train.unique()[-1]\n",
        "train_idx = groups_train != val_group\n",
        "val_idx = groups_train == val_group\n",
        "\n",
        "X_tr_lgb, y_tr_lgb = X_train_full[train_idx], y_train[train_idx]\n",
        "X_val_lgb, y_val_lgb = X_train_full[val_idx], y_train[val_idx]\n",
        "\n",
        "# LightGBM Parameters (Optimised for Log Loss)\n",
        "params = {\n",
        "    'objective': 'binary',\n",
        "    'metric': 'binary_logloss',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 31,\n",
        "    'learning_rate': 0.05,\n",
        "    'feature_fraction': 0.9,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'verbose': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "train_data = lgb.Dataset(X_tr_lgb, label=y_tr_lgb)\n",
        "val_data = lgb.Dataset(X_val_lgb, label=y_val_lgb, reference=train_data)\n",
        "\n",
        "print(\" Training LightGBM...\")\n",
        "bst = lgb.train(\n",
        "    params,\n",
        "    train_data,\n",
        "    num_boost_round=1000,\n",
        "    valid_sets=[train_data, val_data],\n",
        "    callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
        ")\n",
        "\n",
        "# Predictions (Uncalibrated)\n",
        "y_pred_uncal = bst.predict(X_test_full, num_iteration=bst.best_iteration)\n",
        "loss_uncal = log_loss(y_test, y_pred_uncal)\n",
        "print(f\" Uncalibrated Log Loss: {loss_uncal:.4f}\")\n",
        "\n",
        "# Calibration Step (Isotonic Regression)\n",
        "print(\" Applying Post-Hoc Calibration (Isotonic)...\")\n",
        "# We calibrate on the validation set predictions\n",
        "val_preds = bst.predict(X_val_lgb, num_iteration=bst.best_iteration)\n",
        "iso = IsotonicRegression(out_of_bounds='clip')\n",
        "iso.fit(val_preds, y_val_lgb)\n",
        "\n",
        "# Final Calibrated Predictions\n",
        "y_pred_cal = iso.transform(y_pred_uncal)\n",
        "loss_cal = log_loss(y_test, y_pred_cal)\n",
        "print(f\" Calibrated Log Loss:   {loss_cal:.4f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 6: EVALUATION & REPORTING\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 6: FINAL EVALUATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Calculate ECE (Expected Calibration Error)\n",
        "def calculate_ece(y_true, y_pred, bins=15):\n",
        "    bin_edges = np.linspace(0, 1, bins + 1)\n",
        "    ece = 0.0\n",
        "    for i in range(bins):\n",
        "        mask = (y_pred >= bin_edges[i]) & (y_pred < bin_edges[i+1])\n",
        "        if mask.sum() > 0:\n",
        "            conf = y_pred[mask].mean()\n",
        "            acc = y_true[mask].mean()\n",
        "            ece += (mask.sum() / len(y_true)) * np.abs(conf - acc)\n",
        "    return ece\n",
        "\n",
        "ece_final = calculate_ece(y_test, y_pred_cal)\n",
        "brier_final = brier_score_loss(y_test, y_pred_cal)\n",
        "\n",
        "# Save final report to 'progression' folder\n",
        "report_path = os.path.join(OUTPUT_DIR, 'FINAL_REPORT.txt')\n",
        "with open(report_path, 'w') as f:\n",
        "    f.write(\"CS2 PREDICTION MODEL - FINAL RESULTS\\n\")\n",
        "    f.write(\"====================================\\n\")\n",
        "    f.write(f\"Baseline B (Economy):  {loss_base:.4f}\\n\")\n",
        "    f.write(f\"Main Model (Calibrated): {loss_cal:.4f}\\n\")\n",
        "    f.write(f\"Improvement:           {(loss_base - loss_cal)/loss_base*100:.2f}%\\n\\n\")\n",
        "    f.write(f\"Brier Score:           {brier_final:.4f}\\n\")\n",
        "    f.write(f\"ECE (Calibration):     {ece_final:.4f}\\n\")\n",
        "\n",
        "print(f\" Final ECE: {ece_final:.4f}\")\n",
        "print(f\" Report saved to: {report_path}\")\n",
        "\n",
        "# Plot Calibration Curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n",
        "prob_true, prob_pred = sns.calibration.calibration_curve(y_test, y_pred_cal, n_bins=10)\n",
        "plt.plot(prob_pred, prob_true, marker='o', label='Main Model')\n",
        "plt.title(f'Reliability Diagram (ECE: {ece_final:.4f})')\n",
        "plt.xlabel('Predicted Probability')\n",
        "plt.ylabel('True Win Rate')\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, 'calibration_curve.png'))\n",
        "print(f\" Calibration plot saved to: {os.path.join(OUTPUT_DIR, 'calibration_curve.png')}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\" PIPELINE COMPLETE SUCCESSFULLY\")\n",
        "print(\"=\" * 80)"
      ]
    }
  ]
}